%%%% PLEASE REPLACE ENTIRELY WITH YOUR OWN CONTENT %%%%


\chapter{Methodology / project development}

This chapter details the methodology used to execute the project, providing a clear and concise description of the approaches and techniques implemented to ensure replicability and academic rigor. It not only covers the research methods and measurement techniques but also delves into specific aspects of software development and project structuring. Whether the project involves computational modeling, algorithm implementation and software optimization, this section explains how each component contributes to the overall objectives.

Additionally, the chapter provides justifications for selecting specific methods over alternatives. For instance, the \textbf{PennyLane} framework was chosen over \textbf{Qiskit} for quantum simulations due to its robust documentation and practical examples in molecular simulations. The adoption of the \textbf{Variational Quantum Eigensolver (VQE)} algorithm was motivated by its compatibility with Noisy Intermediate-Scale Quantum (NISQ) devices. Parallelization strategies were implemented to enhance computational efficiency and reduce execution times.

The project follows a modular structure that facilitates scalability and simplifies the integration of new functionalities. The codebase is organized into configuration files, main execution scripts, and core computational modules. Furthermore, the adaptive construction of the \textit{ansatz} and operator selection processes are described, highlighting how these techniques improve the accuracy and efficiency of quantum simulations.

Finally, the chapter addresses the limitations of the chosen methodologies and the strategies applied to mitigate these challenges. These include managing framework stability issues, computational resource constraints, and optimization convergence difficulties. By transparently discussing the strengths and weaknesses, this section presents a balanced view of the development process, emphasizing its reliability and robustness.

\section{Tools and Frameworks Selection}
To achieve the objectives of our project, the first essential step was to select the framework to be used throughout the development process. This decision was essential, as it directly influenced the progress and success of the project.

To make the decision on which framework to use, we compared the documentation of the two quantum simulation frameworks available in the market: \textit{PennyLane} and \textit{Qiskit}. These are the most comprehensive frameworks with similar features available at the time of creating this project. After reviewing the documentation, we ultimately chose to use \textit{PennyLane} for two reasons.

The first reason was the amount of documentation related to quantum simulation. Once we started looking into how others were using these resources, we realized that in the field of molecular simulation, the existing documentation—both theoretical and especially practical—was substantially greater. This provided us with more examples to begin developing our project and a more extensive theoretical background to understand the concepts we were working with.

The second reason for our choice was the frequent major changes implemented by \textit{Qiskit}. We realized that while \textit{Qiskit} is a tool that promises to be high capable, it has historically undergone significant structural changes. For these reasons, this project has been developed using the \textit{PennyLane} framework.

\section{Project Structuring}

After selecting the interface and implementing the initial version of the code, we reorganized the project to achieve a more modular architecture. This revised organization not only makes it easier to add new functionalities but also ensures that the project can handle higher levels of complexity. Below, we present the layout of the project and the functionality of each directory and file.

\subsection{Code Organization}
\begin{ProjectStructure}
  \texttt{quantum\_simulation\_project/}
  \begin{itemize}[label={}, left=1em]
      \item \texttt{config/}
      \begin{itemize}[label={}, left=2em]
          \item \texttt{config\_functions.py}: Configuration functions for the project.
          \item \texttt{molecules.json}: JSON file containing molecular data.
      \end{itemize}
      \item \texttt{main.py}: The main entry point for the program.
      \item \texttt{modules/}
      \begin{itemize}[label={}, left=2em]
          \item \texttt{ansatz\_preparer.py}: Quantum ansatz preparation.
          \item \texttt{hamiltonian\_builder.py}: Molecular Hamiltonian construction.
          \item \texttt{molecule\_manager.py}: Molecular data management.
          \item \texttt{opt\_mol.py}: End-to-end molecular optimization.
          \item \texttt{optimizer.py}: Optimization algorithms.
          \item \texttt{visualizer.py}: Visualization tools.
      \end{itemize}
      \item \texttt{temp\_results\_autograd/}
      \begin{itemize}[label={}, left=2em]
          \item \texttt{energy\_evolution.png}: Graph of energy convergence.
          \item \texttt{filtered\_report\_autograd.txt}: Filtered results report.
          \item \texttt{final\_geometries\_3D.png}: Final 3D geometries.
          \item \texttt{nuclear\_coordinates.png}: Nuclear coordinates visualization.
          \item \texttt{output.txt}: Program output log.
          \item \texttt{profile\_output\_autograd.txt}: Autograd profiling output.
      \end{itemize}
      \item \texttt{test/}: Directory for tests.
  \end{itemize}
\end{ProjectStructure}

\subsection{Main Directory}
\begin{itemize}
    \item \texttt{main.py}:
    Central entry point of the program. It initializes the process by selecting molecules, configuring the optimizer, and setting up the ansatz. It also manages the optimization workflow, handles result storage, and produces comprehensive reports. Profiling tools evaluate computational performance.
\end{itemize}

\subsection{\texttt{config/} Directory}
\begin{itemize}
    \item \texttt{config\_functions.py}:
    Handles project configuration. This includes loading molecular data, selecting optimization algorithms, and setting initial parameters such as ansatz type and convergence tolerance. The module also allows adding custom molecules and organizing saved results.
    \item \texttt{molecules.json}:
    A structured JSON file containing information about molecules, including atomic symbols, coordinates, charges, and spin multiplicities.
\end{itemize}

\subsection{\texttt{modules/} Directory}
Core computational logic resides here:
\begin{itemize}
    \item \texttt{ansatz\_preparer.py}:
    Implements quantum circuit construction (ansätze) for both adaptive and traditional methods. Includes the UCCSD ansatz (single and double excitations) and hardware-efficient ansatzes featuring multiple circuit layers.
    \item \texttt{hamiltonian\_builder.py}:
    Constructs the molecular Hamiltonian, a fundamental component of quantum simulations. Calculates Hartree-Fock reference states and can extract exact energy values from the Hamiltonian matrix.
    \item \texttt{molecule\_manager.py}:
    Initializes molecules by processing atomic symbols, initial coordinates, and configuration parameters such as charge and multiplicity. Also computes important properties like the number of electrons and orbitals.
    \item \texttt{optimizer.py}:
    Contains optimization algorithms (e.g., Adam, QNG, RMSProp). Integrates parameter updates and nuclear coordinate adjustments in a unified optimization framework.
    \item \texttt{opt\_mol.py}:
    Orchestrates the complete molecular optimization pipeline. Brings together Hamiltonian construction, molecule management, optimization routines, and result visualization.
    \item \texttt{visualizer.py}:
    Offers visualization tools for energy convergence and molecular geometries. Generates detailed graphical outputs in both linear and logarithmic scales.
\end{itemize}

\subsection{\texttt{temp\_results\_autograd/} Directory}
Contains intermediate results generated during simulations:
\begin{itemize}
    \item \texttt{energy\_evolution.png}: Graph of energy convergence over iterations.
    \item \texttt{nuclear\_coordinates.png}: Visualization of nuclear coordinates during optimization.
    \item \texttt{filtered\_report\_autograd.txt}: Filtered report of relevant profiling metrics.
    \item \texttt{output.txt}: Primary output log of the program.
\end{itemize}

\section{Implementation of the VQE}
Before delving into how molecular energy optimization has been implemented, it is crucial to first detail the methodology employed for optimizing the system parameters. This process was conducted using the \textit{Variational Quantum Eigensolver} (VQE), which was selected as the primary method to estimate the ground state energy of the quantum system under study.

The VQE algorithm integrates limited quantum processing, characterized by measurements and shallow quantum circuits, with classical optimization techniques. Its selection is grounded on the following justifications:

\begin{itemize}
    \item \textbf{Suitability for NISQ devices:} VQE is particularly well-suited for noisy intermediate-scale quantum (NISQ) devices, as it requires circuits of relatively low depth.
    \item \textbf{Flexible Ansatz:} It allows the use of various adaptive variational ansätze that capture essential electronic correlations.
    \item \textbf{Direct coupling to classical optimizers:} The VQE cost function (the expected energy) can be minimized with a wide range of classical methods, making it easy to experiment with different optimizers.
\end{itemize}

The core principle of VQE is the variational theorem, which guarantees that the expected energy of the ansatz is always an upper bound to the true ground state energy. By optimizing the ansatz parameters, the algorithm progressively approaches the actual energy minimum. We have already explained the concept of VQE in the state of the art chapter; now we will explain how we have implemented it in our project and how we have integrated it.

\begin{ProjectStructure}
    \textbf{Principle of VQE:}

    The VQE is based on the variational principle, which states that the expected energy of any approximate state \( |\psi(\theta)\rangle \) is always greater than or equal to the real ground state energy \( E_0 \):

    \[
    E(\theta) = \langle \psi(\theta) | H | \psi(\theta) \rangle \geq E_0
    \]

    We have already discussed this concept, but it is necessary to emphasize it as it is the foundation of the entire algorithm. The idea is to find the parameters \( \theta \) that minimize the expected energy, thereby approaching the real value of the ground state energy.
\end{ProjectStructure}

Next, we will explore the implementation of the VQE within our project, breaking down its key components. Each element plays a crucial role in ensuring the algorithm's accuracy and efficiency: the molecular Hamiltonian defines the energy landscape, the ansatz captures electronic correlations through parameterized quantum circuits and the cost function evaluates the expected energy, guiding the optimization. This section outlines how each of these components was designed and integrated to maximize performance and precision.

\subsection{Hamiltonian Construction Process}

\begin{enumerate}
    \item \textbf{Definition of Molecular Geometry:}

    Initially, it is necessary to define the molecular geometry of the system to be studied. This information includes the atomic symbols and the initial coordinates of the nuclei. In our project, this data is stored in a JSON file, which is loaded and processed to initialize the molecule. However, custom molecules can also be added directly in the code. 

    This part of the code provides the user with the ability to select the molecule to be simulated, allowing them to choose between the predefined molecules in the JSON file or add a new one. The \texttt{from\_user\_input} function loads the molecular information and initializes it, preparing it for simulation.

    \item \textbf{Hamiltonian Construction:}

    Once the molecular geometry is defined, the next step is to construct the system's Hamiltonian. This Hamiltonian represents the total energy of the system and is fundamental for quantum simulation. In our project, the Hamiltonian is constructed using the \texttt{build\_hamiltonian} function, which transforms the electronic Hamiltonian from its second-quantized form into a qubit-based representation. This implementation is relatively straightforward as it relies on PennyLane's \texttt{molecular\_hamiltonian} function, which generates the Hamiltonian from the atomic symbols, coordinates, and other system parameters.

    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
      title=Hamiltonian Build, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
      listing options={language=Python, basicstyle=\ttfamily\small,
      showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt, breaklines=true}}
def build_hamiltonian(x, symbols, charge=0, mult=1, basis_name='sto-3g'):
    x = np.array(x)
    coordinates = x.reshape(-1, 3)
    hamiltonian, qubits = qml.qchem.molecular_hamiltonian(
        symbols, coordinates, charge=charge, mult=mult, basis=basis_name
    )
    h_coeffs, h_ops = hamiltonian.terms()
    h_coeffs = np.array(h_coeffs)
    return qml.Hamiltonian(h_coeffs, h_ops)
    \end{tcblisting}

    \noindent\textbf{Note:}
    A basis set, such as \texttt{sto-3g}, is chosen to represent atomic orbitals. This predefined set of basis functions simplifies the simulation while retaining sufficient accuracy for many molecular systems.

    \bigskip
    Apart from transforming the electronic Hamiltonian, initially expressed in its second-quantized form, into a qubit-based representation suitable for quantum computation, this function also allows the inclusion of user-defined parameters, such as the net molecular charge and the spin multiplicity, providing flexibility to simulate a wide range of electronic states. This feature is particularly important for accurately representing systems with different charge states and spin configurations.

    Furthermore, it optionally supports the definition of an active space, allowing the focus to be limited to the most relevant orbitals and electrons, thus optimizing resource usage without sacrificing significant accuracy.

\end{enumerate}


\subsection{Adaptive Ansatz Construction and Operator Selection}

For the construction of the ansatz, we use the adaptive ansatz construction builds upon the conventional variational approach by strategically selecting only those excitations that offer the most significant energy reductions. Instead of starting from a large, fixed set of parameters, the algorithm begins with the Hartree-Fock state and incrementally introduces new excitations based on their calculated impact on lowering the system’s energy. This methodology provides both theoretical and practical advantages in handling the complexity of the solution space.

The selection process begins with a predefined \textit{operator pool}, consisting of single and double excitation operators relevant to the molecular system. At the start of the procedure, no variational parameters are assigned, and the system is initialized in the reference Hartree-Fock state. At each iteration, the algorithm evaluates the energy gradients associated with adding each operator from the pool.

The following outlines the main steps of the adaptive ansatz construction and operator selection process, all implemented on the \texttt{ansatz\_preparer.py} file:

\begin{enumerate}
    \item \textbf{Gradient Calculation:} For every candidate operator $\hat{O}_i$ in the pool, the partial derivative of the energy with respect to the parameter controlling $\hat{O}_i$ is computed. This step identifies how sensitive the energy is to introducing that particular excitation. In our project this functionality is implemented in the \texttt{compute\_operator\_gradients} function.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Gradient Calculation, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt, breaklines=true}}
def compute_operator_gradients(operator_pool, selected_excitations, params, hamiltonian, hf_state, dev, spin_orbitals, ansatz_type="uccsd"): 
    gradients = []
    for gate_wires in operator_pool:
        param_init_autograd = np.array(0.0, requires_grad=True)
    
        @qml.qnode(dev, interface="autograd")
        def circuit_with_gate(param):
            prepare_ansatz(params, hf_state, selected_excitations, spin_orbitals, ansatz_type=ansatz_type)
            if len(gate_wires) == 2:
                qml.SingleExcitation(param, wires=gate_wires)
            elif len(gate_wires) == 4:
                qml.DoubleExcitation(param, wires=gate_wires)
            return qml.expval(hamiltonian)
    
        grad_fn_autograd = qml.grad(circuit_with_gate, argnum=0)
        grad = grad_fn_autograd(param_init_autograd)
        gradients.append(np.abs(grad))
    
    return gradients
      \end{tcblisting}
    
    \item \textbf{Operator Ranking and Filtering:} All candidate excitations are ranked according to the absolute value of their gradients. Operators that produce negligible energy changes are discarded, while those offering substantial decreases are selected for inclusion. The \texttt{select\_operator} function implements this filtering process.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Operation Ranking, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt, breaklines=true}}
def select_operator(gradients, operator_pool, convergence):
    if len(gradients) == 0 or np.all(np.isnan(gradients)):
        return None, None

    max_grad_index = np.argmax(gradients)
    max_grad_value = gradients[max_grad_index]

    if max_grad_value < convergence:
        return None, None
    selected_gate = operator_pool[max_grad_index]
    return selected_gate, max_grad_value
      \end{tcblisting}
    \item \textbf{Incremental Ansatz Growth:} The selected operator(s) is then added to the ansatz. A new parameter is introduced and optimized, increasing the dimensionality of the parameter space. This targeted expansion ensures that each additional parameter contributes meaningfully to lowering the energy. The incremental ansatz is implemented as follows:
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Operation Ranking, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt, breaklines=true}}
def prepare_ansatz_uccsd(params, hf_state, selected_excitations, spin_orbitals):
    qml.BasisState(hf_state, wires=range(spin_orbitals))
    for i, exc in enumerate(selected_excitations):
        if len(exc) == 2:
            qml.SingleExcitation(params[i], wires=exc)
        elif len(exc) == 4:
            qml.DoubleExcitation(params[i], wires=exc)
      \end{tcblisting}
    \item \textbf{Pool Update and Iteration:} After adding the chosen operators, the process repeats. The operator pool is re-examined at subsequent steps, but it now excludes previously chosen operators unless they are included as parameterized parts of the ansatz. Over multiple iterations, the ansatz evolves adaptively, selecting the most relevant subset of excitations.
\end{enumerate}

Below, we can observe a simplified code snippet, consistent with the project’s implementation, showcasing the adaptive operator selection process:

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
  title=Adaptive Operator Selection, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
  listing options={language=Python, basicstyle=\ttfamily\small,
  showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt, breaklines=true}}
gradients = compute_operator_gradients(operator_pool, selected_excitations, params, hamiltonian, hf_state, dev, spin_orbitals)
selected_gate, max_grad_value = select_operator(gradients, operator_pool, convergence_threshold)
if selected_gate:
    selected_excitations.append(selected_gate)
    params = np.append(params, 0.0)  # Add new parameter for the chosen operator
    print(f"Added operator {selected_gate} with gradient {max_grad_value:.5e}")
else:
    print("No significant operators found. Convergence or local minimum reached.")
\end{tcblisting}
\subsubsection{Adaptive Ansatz Benefits}
In summary, this code uses the \texttt{compute\_operator\_gradients} function to evaluate each operator’s gradient, while the \texttt{select\_operator} function applies a filtering criterion based on a defined \texttt{convergence\_threshold}. Only the most promising excitation is incorporated into the ansatz at each step, ensuring a controlled and meaningful expansion of the parameter space.

In numerical experiments, this targeted approach has demonstrated:
\begin{itemize}
    \item \textbf{Faster Convergence:} Fewer parameters are introduced at each stage, allowing the optimizer to quickly reduce the energy without wading through irrelevant configurations.
    \item \textbf{Lower Resource Consumption:} By refining the search space, the quantum circuits remain relatively shallow, and classical optimization routines require fewer evaluations.
    \item \textbf{Scalability:} As molecular systems grow in complexity, the adaptive approach helps mitigate the exponential growth in parameter number, making it more feasible to handle larger systems within similar computational budgets.
\end{itemize}


\subsection{Cost Function Definition}
With the ansatz defined, the next step is to establish a cost function that evaluates the expected energy of the system given a set of parameters \(\theta\). In our implementation, this cost function is defined within \texttt{update\_parameters\_and\_coordinates} and calculates the expected value of the molecular Hamiltonian:
  
  \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Definition of the Cost Function, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt, breaklines=true}}
@qml.qnode(dev, interface=interface)
def cost_fn(params):
    prepare_ansatz(params, hf_state, selected_excitations, spin_orbitals)
    return qml.expval(hamiltonian)
  \end{tcblisting}
  
In our implementation, \texttt{prepare\_ansatz} serves as an auxiliary function that enables the selection of the desired ansatz for implementation. This flexibility has also allowed us to compare the effectiveness of the UCCSD ansatz against other ansätze. Below is the function that facilitates the selection of the ansatz to be used:

  
  \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Ansatz Selection, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt, breaklines=true}}
def prepare_ansatz(params, hf_state, selected_excitations, spin_orbitals, ansatz_type="uccsd", num_layers = 10):
    if ansatz_type not in ANSATZ_MAP:
        raise ValueError(f"Ansatz type '{ansatz_type}' is not recognized. Available: {list(ANSATZ_MAP.keys())}")

    ansatz_fn = ANSATZ_MAP[ansatz_type]

    if ansatz_type == "uccsd":
        ansatz_fn(params, hf_state, selected_excitations, spin_orbitals)
    else:
        ansatz_fn(num_layers,params, hf_state, [], spin_orbitals)
    \end{tcblisting}
This function is essential for evaluating \(E(\theta)\). By calculating the expected value of the Hamiltonian, we can quantify how close our approximate state is to the true ground state.
\section{Mixed Optimization Strategy}

In this work, both the variational parameters \(\theta\) (electronic) and the nuclear coordinates \(\mathbf{X}\) (geometric) are refined within a single iterative loop. This coupled approach ensures that each electronic update reflects the current molecular geometry, while each geometric update leverages the most accurate electronic wavefunction available. By jointly optimizing \(\theta\) and \(\mathbf{X}\), the algorithm can converge more efficiently to a physically meaningful global minimum.

\subsection{Rationale for a Coupled Scheme}
Traditional sequential approaches often optimize electronic parameters at a fixed geometry, then update the geometry using the finalized electronic structure. Such a split workflow can lead to unnecessary iterations and less-precise intermediate results. Because the electronic distribution and the molecular geometry are inherently interdependent, we opt to update both simultaneously, thereby reducing computational overhead and converging more smoothly to the system's equilibrium configuration.

\subsection{Iterative Optimization Steps}
The key steps of the coupled optimization process, implemented in the \textit{run\_optimization\_uccsd} function within the \texttt{optimizer.py} file, are described below:
\begin{enumerate}
    \item \textbf{Initialization:}
    First, we define the initial geometry \(\mathbf{X}_0\), variational parameters \(\theta_0\), and other required structures.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Initialization, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
import pennylane as qml
from pennylane import numpy as np

# In run_single_optimizer (lines near 290+ in the code):
params = np.array([], requires_grad=True)  # Starting with empty parameters
operator_pool_copy = operator_pool.copy()
selected_excitations = []
x = x_init.copy()  # Copy of the initial geometry

# Set up the environment for optimization:
exact_energy = compute_exact_energy(symbols, x_init, charge, mult, basis_name)
hf_state = generate_hf_state(electrons, spin_orbitals)
dev = qml.device("default.qubit", wires=spin_orbitals)
    \end{tcblisting}

    \item \textbf{Hamiltonian Recalculation:}
    Then, at each iteration, the molecular Hamiltonian is rebuilt for the current geometry \(\mathbf{X}\). This step ensures that the energy evaluation remains accurate and up-to-date with the latest nuclear configuration on each optimization cycle.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Hamiltonian Recalculation, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
# In run_optimization_uccsd (lines near 124+):
for iteration in range(max_iterations):
    # Rebuild the Hamiltonian for the current geometry 'x'
    hamiltonian = build_hamiltonian(x, symbols, charge, mult, basis_name)
    
    # Additional iteration logic follows:
    \end{tcblisting}

    \item \textbf{Electronic Update via Operator Gradients:}
    The next step is to compute the energy gradient with respect to a pool of candidate excitation operators. We select the operator that yields the largest energy decrease and add it to the ansatz. This strategy expands the variational parameter space only in directions that significantly reduce the energy.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Electronic Update, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
# Same loop in run_optimization_uccsd:
gradients = compute_operator_gradients(
    operator_pool_copy,
    selected_excitations,
    params,
    hamiltonian,
    hf_state,
    dev,
    spin_orbitals,
    ansatz_type="uccsd"
)

selected_gate, max_grad_value = select_operator(gradients, operator_pool_copy, CONV)
if selected_gate is None:
    print("No operators selected. Stopping optimization for uccsd.")
    break

selected_excitations.append(selected_gate)
params = np.append(params, 0.0)  # Add a new variational parameter
params = np.array(params, requires_grad=True)
print(f"Added operator {selected_gate} with gradient {max_grad_value:.5e}")
    \end{tcblisting}

    \item \textbf{Geometric Update via Finite Differences:}
    On the same iteration, we update the geometry by numerically approximating \(\nabla_{\mathbf{X}}E(\theta, \mathbf{X})\)through small perturbations to each coordinate. The geometry is then updated as follows:
    \[
    \mathbf{X} \leftarrow \mathbf{X} \;-\; \alpha\, \nabla_{\mathbf{X}} E(\theta, \mathbf{X}),
    \]
    where \(\alpha\) is a suitably chosen learning rate. This technique avoids overly complex gradient calculations while remaining flexible and straightforward to implement.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Geometric Update, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
# In update_parameters_and_coordinates (lines near 59+):
grad_x = compute_nuclear_gradients(
    params, x, symbols, selected_excitations, dev,
    hf_state, spin_orbitals, interface, charge, mult, basis_name
)

# Apply the update:
x = x - learning_rate_x * grad_x
    \end{tcblisting}

    \item \textbf{Convergence Checks:}
    Then, we impose strict thresholds on both the change in total energy and the geometric displacements. Once these criteria are satisfied, the geometry is deemed optimized and stable, and the refinement process is terminated.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Convergence Checks, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
# In update_parameters_and_coordinates (lines near 52+):
energy = np.real(energy)
if check_convergence(energy, prev_energy, recent_diffs):
    print(f"Convergence reached updating parameters and coordinates: Energy difference < {CONV}")
    converged = True
    prev_energy = energy
    # Code returns early, finalizing this substep

    \end{tcblisting}

    \item \textbf{Visualization and Termination:}
    Finally, we track the evolution of energy and geometry at every iteration, providing immediate graphical feedback (e.g., energy vs.\ iteration plots). This step helps identify convergence, reveals unexpected behaviors early, and confirms when additional optimization no longer benefits the system.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Visualization and Termination, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
# Example of final printout and logging in run_optimization_uccsd:
print(f"Iteration {iteration + 1}, Energy = {current_energy:.8f} Ha, Max Gradient = {max_grad_value:.5e}")

# After all iterations or once convergence is reached:
print(f"Total optimization time (uccsd): {total_time:.2f} seconds")
print(f"Final energy with {optimizer_name} (autograd) = {final_energy:.8f} Ha")
print(f"Difference from exact (FCI) energy: {diff:.8e} Ha")

# Geometry and circuit details are saved or printed:
for i, atom in enumerate(symbols):
    atoms_coords.append([atom, final_x_np[3*i], final_x_np[3*i+1], final_x_np[3*i+2]])
print(tabulate(atoms_coords, headers=["Symbol", "x (A)", "y (A)", "z (A)"], floatfmt=".6f"))
    \end{tcblisting}
\end{enumerate}


\subsection{Efficiency of the Coupled Strategy}
By refining \(\theta\) and \(\mathbf{X}\) concurrently, each electronic update leverages a geometry already progressing toward equilibrium. Likewise, every geometric move reflects the latest improvements to the electronic wavefunction. This synergy minimizes redundant calculations and avoids suboptimal solutions, typically leading to faster, more stable convergence compared to the conventional, decoupled approach.

\section{Parallelization of Executions}
One of the main improvements implemented in the project to accelerate execution and provide greater flexibility in our simulations has been parallelization. To achieve this, it was necessary to adapt the code so that simulations could be executed concurrently. Below, the process followed to enable this functionality is detailed.

\subsection{User Input Management and System Configuration}
To allow the user to configure the different types of simulations, a configuration file was incorporated in the \texttt{config/} directory, named \texttt{config\_functions.py}. This file defines variables that allow specifying, among other things, the type of molecule, the optimizer, and the \emph{ansatz}:

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=User Input Management, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
parser = argparse.ArgumentParser(description='Quantum simulation of molecules using VQE.')
parser.add_argument('--molecule', type=str, nargs='+', help='Molecule(s) to simulate.')
parser.add_argument('--optimizer', type=str, nargs='+', help='Optimizers to use (Adam, Adagrad, etc.).')
parser.add_argument('--stepsize', type=float, nargs='+', default=[0.4], help='Optimizer step size(s).')
parser.add_argument('--ansatz', type=str, nargs='+', help='Ansatz to use (e.g. uccsd, vqe_classic).')
args = parser.parse_args()
\end{tcblisting}

Before starting each simulation, two key lists are constructed:
\begin{itemize}
    \item One with the optimizers to be used for each execution.
    \item Another with the additional parameters (the type of \emph{ansatz}, the number of layers, the number of optimizations, etc.).
\end{itemize}

The \texttt{build\_optimizers} function automatically generates the optimizers and organizes these parameters:

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Generation of optimizers, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
def build_optimizers(args, ansatz_list, optimizer_map, predefined_steps):
    optimizers, new_ans = {}, []
    if args.all_optimizers:
        all_opts = list(optimizer_map.keys())
        user_steps = (args.stepsize != [0.4] or len(args.stepsize) > 1)
        for opt in all_opts:
            steps_for_opt = args.stepsize if user_steps else [predefined_steps[opt]]
            for step in steps_for_opt:
                for n in args.opt_step:
                    for ans_type, layer in ansatz_list:
                        name = f"{opt}_{step}_{ans_type}_{layer}layers_{n}steps"
                        optimizers[name] = optimizer_map[opt](stepsize=step)
                        new_ans.append((ans_type, layer, n))
    elif args.optimizer:
        for opt in args.optimizer:
            if opt not in optimizer_map:
                print(f"Error: Optimizer '{opt}' not recognized.")
                sys.exit(1)
            for step in args.stepsize:
                for n in args.opt_step:
                    for ans_type, layer in ansatz_list:
                        name = f"{opt}_{step}_{ans_type}_{layer}layers_{n}steps"
                        optimizers[name] = optimizer_map[opt](stepsize=step)
                        new_ans.append((ans_type, layer, n))
    else:
        # Default value if neither --optimizer nor --all_optimizers is specified
        for step in args.stepsize:
            for n in args.opt_step:
                for ans_type, layer in ansatz_list:
                    name = f"NMomentum_{step}_{ans_type}_{layer}layers_{n}steps"
                    optimizers[name] = NesterovMomentumOptimizer(stepsize=step)
                    new_ans.append((ans_type, layer, n))
    return optimizers, new_ans
\end{tcblisting}

\subsection{Parallelization of Execution with Multiple Optimizers}
After generating the optimizers and their corresponding configurations, the parallel execution process is invoked. This approach distributes each simulation across different processes using \texttt{ProcessPoolExecutor}, thereby leveraging multiple CPU cores to significantly speed up computation time:


\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Process parallelization, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
with concurrent.futures.ProcessPoolExecutor() as executor:
    futures = []
    cont = 0
    for optimizer_name, opt in optimizers.items():
        if cont < len(ansatz_list):
            ans_type, layers, nsteps = ansatz_list[cont]
        else:
            ans_type, layers, nsteps = ("uccsd", 0, 10)
        cont += 1
        futures.append(
            executor.submit(
                run_single_optimizer,
                optimizer_name, opt, ans_type, layers, nsteps, symbols, x_init, electrons, spin_orbitals, charge,
                mult, basis_name, hf_state, dev, operator_pool, exact_energy, results_dir
            )
        )
\end{tcblisting}

In this way, each optimizer is executed independently, allowing for the maximum utilization of available hardware resources. This accelerates the simulation process and provides greater flexibility in experimenting with different configurations.

\subsection{Compilation of Results and Cleanup of Temporary Files}
After completing the execution of parallel processes, several key steps are carried out to unify results, clean up temporary files, and generate the final results. Each step is detailed below along with the corresponding code.

\subsubsection{Creation and Execution of Parallel Processes}
Parallel processes are created using \texttt{ProcessPoolExecutor}. For each configured optimizer, simulations are submitted as tasks to the executor, and the corresponding \emph{futures} are stored. Once they complete, the results are collected in the \texttt{interface\_results} dictionary.

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Creation and Execution of Parallel Processes, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
# Collect results when processes finish
for future in concurrent.futures.as_completed(futures):
    optimizer_name, data = future.result()
    interface_results[optimizer_name] = data
\end{tcblisting}

\subsubsection{Unification of Results into a Single File}
To centralize the simulation information, the contents of individual output files are combined into a single file named \texttt{combined\_output.txt}.

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Unification of Results into a Single File, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
combined_output_path = os.path.join(results_dir, "combined_output.txt")
with open(combined_output_path, "w", encoding="utf-8") as combined_out:
    for optimizer_name in optimizers.keys():
        output_file = os.path.join(results_dir, f"output_{optimizer_name}.txt")
        if os.path.exists(output_file):
            with open(output_file, "r", encoding="utf-8") as f:
                content = f.read()
            combined_out.write(f"=== Optimizer: {optimizer_name} ===\n")
            combined_out.write(content + "\n")
\end{tcblisting}

\subsubsection{Deletion of Temporary Files}
Once the individual data has been centralized, the temporary output files are deleted to reduce disk space usage and clean the results directory.

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Deletion of Temporary Files, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
for optimizer_name in optimizers.keys():
    output_file = os.path.join(results_dir, f"output_{optimizer_name}.txt")
    if os.path.exists(output_file):
        os.remove(output_file)
\end{tcblisting}

\subsubsection{Generation of Final Results}
The final results, such as the optimized energy, differences from the exact energy, and final molecular geometries, are presented to the user. Additionally, execution times and corresponding quantum circuits are visualized.

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Generation of Final Results, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
print("=== Total Optimization Times ===\n")
for optimizer_name in optimizers.keys():
    final_energy = interface_results[optimizer_name]["final_energy"]
    exact_energy_ref = interface_results[optimizer_name]["exact_energy_reference"]
    diff = final_energy - exact_energy_ref if final_energy is not None else None
    if final_energy is not None:
        print(f"Final energy with {optimizer_name} = {final_energy:.8f} Ha")
        print(f"Difference from exact (FCI) energy: {diff:.8e} Ha\n")
    else:
        print(f"No final energy obtained with {optimizer_name}\n")

    total_time = interface_results[optimizer_name]["execution_times"].get('Total Time', 0)
    print(f"Optimizer: {optimizer_name}, Time: {total_time:.2f} seconds")
\end{tcblisting}

In this way, the complete workflow allows:
\begin{enumerate}
    \item Executing processes in parallel and collecting their results.
    \item Unifying the generated data into a single output file.
    \item Cleaning up temporary files to maintain an organized directory.
    \item Presenting the final results in a clear and detailed manner.
\end{enumerate}
