%%%% PLEASE REPLACE ENTIRELY WITH YOUR OWN CONTENT %%%%


\chapter{Methodology / project development}

In this chapter, the methodology used in the completion of the work will be detailed. Its aim is to offer a thorough account of the approaches and techniques used, ensuring replicability and academic rigor. It will not only cover the research methods and measurement techniques employed but will also delve into the specifics of software and hardware development. Whether the project involves qualitative analysis, quantitative measurements, computational modeling, or physical prototyping, this chapter should elucidate how each component contributes to the overall objectives.

In addition to describing the methods themselves, the chapter will also provide justifications for why specific methods were chosen over others. For example, it may explain the choice of a particular programming language, statistical test, or experimental setup. The chapter will also address the limitations of the methodology and how these have been mitigated or accounted for. Readers should come away with a clear understanding of how the project's development has been carried out, why certain choices were made, and how these methods serve to fulfill the initially established objectives.

\section{Tools and Frameworks Selection}
To achieve the objectives of our project, the first crucial step was to select the framework to be used throughout the development process. This decision was essential, as it directly influenced the progress and success of the project.

To make the decision on which framework to use, we compared the documentation of the two quantum simulation frameworks available in the market: PennyLane and Qiskit. These are the most comprehensive frameworks with similar features available at the time of creating this project. After reviewing the documentation, we ultimately chose to use PennyLane for two reasons.

The first reason was the amount of documentation related to quantum simulation. Once we started looking into how others were using these resources, we realized that in the field of molecular simulation, the existing documentation—both theoretical and especially practical—was substantially greater. This provided us with more examples to begin developing our project and a more extensive theoretical background to understand the concepts we were working with.

The second reason for our choice was the frequent major changes implemented by Qiskit. We realized that while Qiskit is a tool that promises to be very good, it has historically undergone significant structural changes. For these reasons, this project has been developed using the PennyLane framework.

\section{Project Structuring}

After selecting the interface and implementing the initial version of the code, we reorganized the project to achieve a more modular structure. This revised organization not only makes it easier to add new functionalities but also ensures that the project can handle higher levels of complexity.

\subsection{Code Organization}
\begin{ProjectStructure}
  \texttt{quantum\_simulation\_project/}
  \begin{itemize}[label={}, left=1em]
      \item \texttt{config/}
      \begin{itemize}[label={}, left=2em]
          \item \texttt{config\_functions.py}: Configuration functions for the project.
          \item \texttt{molecules.json}: JSON file containing molecular data.
      \end{itemize}
      \item \texttt{main.py}: The main entry point for the program.
      \item \texttt{modules/}
      \begin{itemize}[label={}, left=2em]
          \item \texttt{ansatz\_preparer.py}: Quantum ansatz preparation.
          \item \texttt{hamiltonian\_builder.py}: Molecular Hamiltonian construction.
          \item \texttt{molecule\_manager.py}: Molecular data management.
          \item \texttt{opt\_mol.py}: End-to-end molecular optimization.
          \item \texttt{optimizer.py}: Optimization algorithms.
          \item \texttt{visualizer.py}: Visualization tools.
      \end{itemize}
      \item \texttt{temp\_results\_autograd/}
      \begin{itemize}[label={}, left=2em]
          \item \texttt{energy\_evolution.png}: Graph of energy convergence.
          \item \texttt{filtered\_report\_autograd.txt}: Filtered results report.
          \item \texttt{final\_geometries\_3D.png}: Final 3D geometries.
          \item \texttt{nuclear\_coordinates.png}: Nuclear coordinates visualization.
          \item \texttt{output.txt}: Program output log.
          \item \texttt{profile\_output\_autograd.txt}: Autograd profiling output.
      \end{itemize}
      \item \texttt{test/}: Directory for tests.
  \end{itemize}
\end{ProjectStructure}

\vspace{1em}
\noindent\textbf{Summary of Core Files:}

\subsection{Main Directory}
\begin{itemize}
    \item \texttt{main.py}:
    Central entry point of the program. It initializes the process by selecting molecules, configuring the optimizer, and setting up the ansatz. It also manages the optimization workflow, handles result storage, and produces comprehensive reports. Profiling tools evaluate computational performance.
\end{itemize}

\subsection{\texttt{config/} Directory}
\begin{itemize}
    \item \texttt{config\_functions.py}:
    Handles project configuration. This includes loading molecular data, selecting optimization algorithms, and setting initial parameters such as ansatz type and convergence tolerance. The module also allows adding custom molecules and organizing saved results.
    \item \texttt{molecules.json}:
    A structured JSON file containing information about molecules, including atomic symbols, coordinates, charges, and spin multiplicities.
\end{itemize}

\subsection{\texttt{modules/} Directory}
Core computational logic resides here:
\begin{itemize}
    \item \texttt{ansatz\_preparer.py}:
    Implements quantum circuit construction (ansätze) for both adaptive and traditional methods. Includes the UCCSD ansatz (single and double excitations) and hardware-efficient ansatzes featuring multiple circuit layers.
    \item \texttt{hamiltonian\_builder.py}:
    Constructs the molecular Hamiltonian, a fundamental component of quantum simulations. Calculates Hartree-Fock reference states and can extract exact energy values from the Hamiltonian matrix.
    \item \texttt{molecule\_manager.py}:
    Initializes molecules by processing atomic symbols, initial coordinates, and configuration parameters such as charge and multiplicity. Also computes important properties like the number of electrons and orbitals.
    \item \texttt{optimizer.py}:
    Contains optimization algorithms (e.g., Adam, QNG, RMSProp). Integrates parameter updates and nuclear coordinate adjustments in a unified optimization framework.
    \item \texttt{opt\_mol.py}:
    Orchestrates the complete molecular optimization pipeline. Brings together Hamiltonian construction, molecule management, optimization routines, and result visualization.
    \item \texttt{visualizer.py}:
    Offers visualization tools for energy convergence and molecular geometries. Generates detailed graphical outputs in both linear and logarithmic scales.
\end{itemize}

\subsection{\texttt{temp\_results\_autograd/} Directory}
Contains intermediate results generated during simulations:
\begin{itemize}
    \item \texttt{energy\_evolution.png}: Graph of energy convergence over iterations.
    \item \texttt{nuclear\_coordinates.png}: Visualization of nuclear coordinates during optimization.
    \item \texttt{filtered\_report\_autograd.txt}: Filtered report of relevant profiling metrics.
    \item \texttt{output.txt}: Primary output log of the program.
\end{itemize}

\section{Development and Implementation}

The \textit{Variational Quantum Eigensolver} (VQE) was chosen as the primary method to estimate the ground state energy of the studied quantum system. VQE combines limited quantum processing (measurements and applicability in moderately deep circuits) with classical optimization techniques. Its selection is justified by:

\begin{itemize}
    \item \textbf{Suitability for NISQ devices:} VQE is particularly well-suited for noisy intermediate-scale quantum (NISQ) devices, as it requires circuits of relatively low depth.
    \item \textbf{Flexible Ansatz:} It allows the use of various adaptive variational ansätze that capture essential electronic correlations.
    \item \textbf{Direct coupling to classical optimizers:} The VQE cost function (the expected energy) can be minimized with a wide range of classical methods, making it easy to experiment with different optimizers.
\end{itemize}

The core principle of VQE is the variational theorem, which guarantees that the expected energy of the ansatz is always an upper bound to the true ground state energy. By optimizing the ansatz parameters, the algorithm progressively approaches the actual energy minimum. We have already explained the concept of VQE in the state of the art chapter; now we will explain how we have implemented it in our project and how we have integrated it.

\paragraph{Principle of VQE:}

The VQE is based on the variational principle, which states that the expected energy of any approximate state \( |\psi(\theta)\rangle \) is always greater than or equal to the real ground state energy \( E_0 \):

\[
E(\theta) = \langle \psi(\theta) | H | \psi(\theta) \rangle \geq E_0
\]

We have already discussed this concept, but it is necessary to emphasize it as it is the foundation of the entire algorithm. The idea is to find the parameters \( \theta \) that minimize the expected energy, thereby approaching the real value of the ground state energy.

\bigskip

Next, we will detail how the VQE is implemented in our project, explaining how each component has been developed for trying to achieve the best performance and results.
\subsection{Hamiltonian Construction Process}

\begin{enumerate}
    \item \textbf{Definition of Molecular Geometry:}

    Each molecule is defined by specifying its atomic symbols and Cartesian coordinates:
    
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
      title=Geometry Definition, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
      listing options={language=Python, basicstyle=\ttfamily\small,
      showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt}}
symbols = ['H', 'H']
x_init = np.array([0.0, 0.0, 0.0,  # Hydrogen 1
                   0.0, 0.0, 0.74])  # Hydrogen 2
    \end{tcblisting}

    \item \textbf{Hamiltonian Construction:}

    The \texttt{build\_hamiltonian} function creates the molecular Hamiltonian using PennyLane’s quantum chemistry features. This function transforms the electronic Hamiltonian from second quantization into a qubit-based representation.

    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
      title=Hamiltonian Build, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
      listing options={language=Python, basicstyle=\ttfamily\small,
      showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt, breaklines=true}}
def build_hamiltonian(x, symbols, charge=0, mult=1, basis_name='sto-3g'):
    x = np.array(x)
    coordinates = x.reshape(-1, 3)
    hamiltonian, qubits = qml.qchem.molecular_hamiltonian(
        symbols, coordinates, charge=charge, mult=mult, basis=basis_name
    )
    h_coeffs, h_ops = hamiltonian.terms()
    h_coeffs = np.array(h_coeffs)
    return qml.Hamiltonian(h_coeffs, h_ops)
    \end{tcblisting}

    \noindent\textbf{Note:}
    A basis set, such as \texttt{sto-3g}, is chosen to represent atomic orbitals. This predefined set of basis functions simplifies the simulation while retaining sufficient accuracy for many molecular systems.

    \noindent\textbf{Function Description:}
    \begin{itemize}
        \item Transforms the electronic Hamiltonian into a Pauli-based qubit Hamiltonian suitable for quantum algorithms.
        \item Incorporates user-defined net charge and spin multiplicity, enabling simulation of various electronic states.
        \item Simplifies the computational space with a chosen basis set and, optionally, an active space to focus only on relevant orbitals and electrons.
    \end{itemize}

\end{enumerate}


\subsection{Adaptive Ansatz Construction and Operator Selection}

As we said before, the adaptive ansatz construction builds upon the conventional variational approach by strategically selecting only those excitations that offer the most significant energy reductions. Instead of starting from a large, fixed set of parameters, the algorithm begins with the Hartree-Fock state and incrementally introduces new excitations based on their calculated impact on lowering the system’s energy. This methodology provides both theoretical and practical advantages in handling the complexity of the solution space.

The selection process begins with a predefined \textit{operator pool}, typically composed of single and double excitation operators relevant to the molecular system. At the start of the procedure, no variational parameters are assigned, and the system is initialized in the reference Hartree-Fock state. At each iteration, the algorithm evaluates the energy gradients associated with adding each operator from the pool:

\begin{enumerate}
    \item \textbf{Gradient Calculation:} For every candidate operator $\hat{O}_i$ in the pool, the partial derivative of the energy with respect to the parameter controlling $\hat{O}_i$ is computed. This step identifies how sensitive the energy is to introducing that particular excitation.
    \item \textbf{Operator Ranking and Filtering:} All candidate excitations are ranked according to the absolute value of their gradients. Operators that produce negligible energy changes are discarded, while those offering substantial decreases are selected for inclusion.
    \item \textbf{Incremental Ansatz Growth:} The selected operator(s) is then added to the ansatz. A new parameter is introduced and optimized, increasing the dimensionality of the parameter space \emph{only where it matters}. This targeted expansion ensures that each additional parameter contributes meaningfully to lowering the energy.
    \item \textbf{Pool Update and Iteration:} After adding the chosen operators, the process repeats. The operator pool is re-examined at subsequent steps, but it now excludes previously chosen operators unless they are included as parameterized parts of the ansatz. Over multiple iterations, the ansatz evolves adaptively, honing in on the most relevant subset of excitations.
\end{enumerate}

A simplified code snippet, consistent with the project’s structure, may appear as follows:

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
  title=Adaptive Operator Selection, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
  listing options={language=Python, basicstyle=\ttfamily\small,
  showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt, breaklines=true}}
gradients = compute_operator_gradients(operator_pool, selected_excitations, params, hamiltonian, hf_state, dev, spin_orbitals)
selected_gate, max_grad_value = select_operator(gradients, operator_pool, convergence_threshold)
if selected_gate:
    selected_excitations.append(selected_gate)
    params = np.append(params, 0.0)  # Add new parameter for the chosen operator
    print(f"Added operator {selected_gate} with gradient {max_grad_value:.5e}")
else:
    print("No significant operators found. Convergence or local minimum reached.")
\end{tcblisting}

In this code, the \texttt{compute\_operator\_gradients} function evaluates each operator’s gradient, while the \texttt{select\_operator} function applies a filtering criterion based on a defined \texttt{convergence\_threshold}. Only the most promising excitation is incorporated into the ansatz at each step, ensuring a controlled and meaningful expansion of the parameter space.

In numerical experiments, this targeted approach has demonstrated:
\begin{itemize}
    \item \textbf{Faster Convergence:} Fewer parameters are introduced at each stage, allowing the optimizer to quickly reduce the energy without wading through irrelevant configurations.
    \item \textbf{Lower Resource Consumption:} By refining the search space, the quantum circuits remain relatively shallow, and classical optimization routines require fewer evaluations.
    \item \textbf{Scalability:} As molecular systems grow in complexity, the adaptive approach helps mitigate the exponential growth in parameter number, making it more feasible to handle larger systems within similar computational budgets.
\end{itemize}


\subsection{Cost Function Definition}
With the ansatz defined, the next step is to establish a cost function that evaluates the expected energy of the system given a set of parameters \(\theta\). In our implementation, this cost function is defined within \texttt{update\_parameters\_and\_coordinates} and calculates the expected value of the molecular Hamiltonian:
  
  \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Definition of the Cost Function, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt, breaklines=true}}
@qml.qnode(dev, interface=interface)
def cost_fn(params):
    prepare_ansatz(params, hf_state, selected_excitations, spin_orbitals)
    return qml.expval(hamiltonian)
  \end{tcblisting}
  
This function is essential for evaluating \(E(\theta)\). By calculating the expected value of the Hamiltonian, we can quantify how close our approximate state is to the true ground state.

\subsection{Mixed Electronic and Geometric Optimization Strategy}

In this work, both the variational parameters \(\theta\) (electronic) and the nuclear coordinates \(\mathbf{X}\) (geometric) are refined within a single iterative loop. This coupled approach ensures that each electronic update reflects the current molecular geometry, while each geometric update leverages the most accurate electronic wavefunction available. By jointly optimizing \(\theta\) and \(\mathbf{X}\), the algorithm can converge more efficiently to a physically meaningful global minimum.

\paragraph{Rationale for a Coupled Scheme}
Traditional sequential approaches often optimize electronic parameters at a fixed geometry, then update the geometry using the finalized electronic structure. Such a split workflow can lead to unnecessary iterations and less-precise intermediate results. Because the electronic distribution and the molecular geometry are inherently interdependent, we opt to update both simultaneously, thereby reducing computational overhead and converging more smoothly to the system's equilibrium configuration.

\paragraph{Iterative Optimization Steps}
\begin{enumerate}
    \item \textbf{Initialization:}
    This snippet shows where the code defines the initial geometry \(\mathbf{X}_0\), variational parameters \(\theta_0\), and other required structures.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Initialization, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
import pennylane as qml
from pennylane import numpy as np

# In run_single_optimizer (lines near 290+ in the code):
params = np.array([], requires_grad=True)  # Starting with empty parameters
operator_pool_copy = operator_pool.copy()
selected_excitations = []
x = x_init.copy()  # Copy of the initial geometry

# Set up the environment for optimization:
exact_energy = compute_exact_energy(symbols, x_init, charge, mult, basis_name)
hf_state = generate_hf_state(electrons, spin_orbitals)
dev = qml.device("default.qubit", wires=spin_orbitals)
    \end{tcblisting}

    \item \textbf{Hamiltonian Recalculation:}
    At each iteration, the molecular Hamiltonian is rebuilt for the current geometry \(\mathbf{X}\).
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Hamiltonian Recalculation, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
# In run_optimization_uccsd (lines near 124+):
for iteration in range(max_iterations):
    # Rebuild the Hamiltonian for the current geometry 'x'
    hamiltonian = build_hamiltonian(x, symbols, charge, mult, basis_name)
    
    # Additional iteration logic follows:
    \end{tcblisting}

    \item \textbf{Electronic Update via Operator Gradients:}
    Compute the energy gradient with respect to a pool of candidate excitation operators. Select the operator yielding the largest energy decrease and add it to the ansatz. This strategy expands the variational parameter space only in directions that significantly lower the energy.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Electronic Update, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
# Same loop in run_optimization_uccsd:
gradients = compute_operator_gradients(
    operator_pool_copy,
    selected_excitations,
    params,
    hamiltonian,
    hf_state,
    dev,
    spin_orbitals,
    ansatz_type="uccsd"
)

selected_gate, max_grad_value = select_operator(gradients, operator_pool_copy, CONV)
if selected_gate is None:
    print("No operators selected. Stopping optimization for uccsd.")
    break

selected_excitations.append(selected_gate)
params = np.append(params, 0.0)  # Add a new variational parameter
params = np.array(params, requires_grad=True)
print(f"Added operator {selected_gate} with gradient {max_grad_value:.5e}")
    \end{tcblisting}

    \item \textbf{Geometric Update via Finite Differences:}
    Numerically approximate \(\nabla_{\mathbf{X}}E(\theta, \mathbf{X})\) by slightly perturbing each coordinate. The geometry is then updated by
    \[
    \mathbf{X} \leftarrow \mathbf{X} \;-\; \alpha\, \nabla_{\mathbf{X}} E(\theta, \mathbf{X}),
    \]
    where \(\alpha\) is a suitably chosen learning rate. This technique avoids overly complex gradient calculations while remaining flexible and straightforward to implement.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Geometric Update, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
# In update_parameters_and_coordinates (lines near 59+):
grad_x = compute_nuclear_gradients(
    params, x, symbols, selected_excitations, dev,
    hf_state, spin_orbitals, interface, charge, mult, basis_name
)

# Apply the update:
x = x - learning_rate_x * grad_x
    \end{tcblisting}

    \item \textbf{Convergence Checks:}
    Impose strict thresholds on both the change in total energy (e.g., below \(10^{-8}\) Ha) and on geometric displacements. Once these criteria are met, the geometry is considered optimized and stable, and further refinement is terminated.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Convergence Checks, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
# In update_parameters_and_coordinates (lines near 52+):
energy = np.real(energy)
if check_convergence(energy, prev_energy, recent_diffs):
    print(f"Convergence reached updating parameters and coordinates: Energy difference < {CONV}")
    converged = True
    prev_energy = energy
    # Code returns early, finalizing this substep

    \end{tcblisting}

    \item \textbf{Visualization and Termination:}
    Track the evolution of energy and geometry at every iteration, providing immediate graphical feedback (e.g., energy vs.\ iteration plots). This step helps identify convergence, reveals unexpected behaviors early, and confirms when additional optimization no longer benefits the system.
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
        title=Visualization and Termination, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
        listing options={language=Python, basicstyle=\ttfamily\small,
        showstringspaces=false, numbers=left, numberstyle=\footnotesize,
        stepnumber=1, numbersep=8pt, breaklines=true}}
# Example of final printout and logging in run_optimization_uccsd:
print(f"Iteration {iteration + 1}, Energy = {current_energy:.8f} Ha, Max Gradient = {max_grad_value:.5e}")

# After all iterations or once convergence is reached:
print(f"Total optimization time (uccsd): {total_time:.2f} seconds")
print(f"Final energy with {optimizer_name} (autograd) = {final_energy:.8f} Ha")
print(f"Difference from exact (FCI) energy: {diff:.8e} Ha")

# Geometry and circuit details are saved or printed:
for i, atom in enumerate(symbols):
    atoms_coords.append([atom, final_x_np[3*i], final_x_np[3*i+1], final_x_np[3*i+2]])
print(tabulate(atoms_coords, headers=["Symbol", "x (A)", "y (A)", "z (A)"], floatfmt=".6f"))
    \end{tcblisting}
\end{enumerate}

\paragraph{Efficiency of the Coupled Strategy}
By refining \(\theta\) and \(\mathbf{X}\) concurrently, each electronic update leverages a geometry already progressing toward equilibrium. Likewise, every geometric move reflects the latest improvements to the electronic wavefunction. This synergy minimizes redundant calculations and avoids suboptimal solutions, typically leading to faster, more stable convergence compared to the conventional, decoupled approach.

\section{Parallelization of Executions}
One of the main improvements implemented in the project to accelerate execution and provide greater flexibility in our simulations has been parallelization. To achieve this, it was necessary to adapt the code so that simulations could be executed concurrently. Below, the process followed to enable this functionality is detailed.

\subsection{User Input Management and System Configuration}
To allow the user to configure the different types of simulations, a configuration file was incorporated in the \texttt{config/} directory, named \texttt{config\_functions.py}. This file defines variables that allow specifying, among other things, the type of molecule, the optimizer, and the \emph{ansatz}:

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=User Input Management, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
parser = argparse.ArgumentParser(description='Quantum simulation of molecules using VQE.')
parser.add_argument('--molecule', type=str, nargs='+', help='Molecule(s) to simulate.')
parser.add_argument('--optimizer', type=str, nargs='+', help='Optimizers to use (Adam, Adagrad, etc.).')
parser.add_argument('--stepsize', type=float, nargs='+', default=[0.4], help='Optimizer step size(s).')
parser.add_argument('--ansatz', type=str, nargs='+', help='Ansatz to use (e.g. uccsd, vqe_classic).')
args = parser.parse_args()
\end{tcblisting}

Before starting each simulation, two key lists are constructed:
\begin{itemize}
    \item One with the optimizers to be used for each execution.
    \item Another with the additional parameters (the type of \emph{ansatz}, the number of layers, the number of optimizations, etc.).
\end{itemize}

The \texttt{build\_optimizers} function automatically generates the optimizers and organizes these parameters:

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Generación de optimizadores, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
def build_optimizers(args, ansatz_list, optimizer_map, predefined_steps):
    optimizers, new_ans = {}, []
    if args.all_optimizers:
        all_opts = list(optimizer_map.keys())
        user_steps = (args.stepsize != [0.4] or len(args.stepsize) > 1)
        for opt in all_opts:
            steps_for_opt = args.stepsize if user_steps else [predefined_steps[opt]]
            for step in steps_for_opt:
                for n in args.opt_step:
                    for ans_type, layer in ansatz_list:
                        name = f"{opt}_{step}_{ans_type}_{layer}layers_{n}steps"
                        optimizers[name] = optimizer_map[opt](stepsize=step)
                        new_ans.append((ans_type, layer, n))
    elif args.optimizer:
        for opt in args.optimizer:
            if opt not in optimizer_map:
                print(f"Error: Optimizer '{opt}' not recognized.")
                sys.exit(1)
            for step in args.stepsize:
                for n in args.opt_step:
                    for ans_type, layer in ansatz_list:
                        name = f"{opt}_{step}_{ans_type}_{layer}layers_{n}steps"
                        optimizers[name] = optimizer_map[opt](stepsize=step)
                        new_ans.append((ans_type, layer, n))
    else:
        # Default value if neither --optimizer nor --all_optimizers is specified
        for step in args.stepsize:
            for n in args.opt_step:
                for ans_type, layer in ansatz_list:
                    name = f"NMomentum_{step}_{ans_type}_{layer}layers_{n}steps"
                    optimizers[name] = NesterovMomentumOptimizer(stepsize=step)
                    new_ans.append((ans_type, layer, n))
    return optimizers, new_ans
\end{tcblisting}

\subsection{Parallelization of Execution with Multiple Optimizers}
After generating the optimizers and their corresponding configurations, the parallel execution process is invoked. This approach distributes each simulation across different processes using \texttt{ProcessPoolExecutor}, thereby leveraging multiple CPU cores to significantly accelerate computation time:


\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Paralelización de procesos, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
with concurrent.futures.ProcessPoolExecutor() as executor:
    futures = []
    cont = 0
    for optimizer_name, opt in optimizers.items():
        if cont < len(ansatz_list):
            ans_type, layers, nsteps = ansatz_list[cont]
        else:
            ans_type, layers, nsteps = ("uccsd", 0, 10)
        cont += 1
        futures.append(
            executor.submit(
                run_single_optimizer,
                optimizer_name, opt, ans_type, layers, nsteps, symbols, x_init, electrons, spin_orbitals, charge,
                mult, basis_name, hf_state, dev, operator_pool, exact_energy, results_dir
            )
        )
\end{tcblisting}

In this way, each optimizer is executed independently, allowing for the maximum utilization of available hardware resources. This accelerates the simulation process and provides greater flexibility in experimenting with different configurations.

\subsection{Compilation of Results and Cleanup of Temporary Files}
After completing the execution of parallel processes, several key steps are carried out to unify results, clean up temporary files, and generate the final results. Each step is detailed below along with the corresponding code.

\subsubsection{Creation and Execution of Parallel Processes}
Parallel processes are created using \texttt{ProcessPoolExecutor}. For each configured optimizer, simulations are submitted as tasks to the executor, and the corresponding \emph{futures} are stored. Once they complete, the results are collected in the \texttt{interface\_results} dictionary.

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Creation and Execution of Parallel Processes, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}

# Collect results when processes finish
for future in concurrent.futures.as_completed(futures):
    optimizer_name, data = future.result()
    interface_results[optimizer_name] = data
\end{tcblisting}

\subsubsection{Unification of Results into a Single File}
To centralize the simulation information, the contents of individual output files (\texttt{output\_\{optimizer\_name\}.txt}) are combined into a single file named \texttt{combined\_output.txt}.

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Unification of Results into a Single File, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
combined_output_path = os.path.join(results_dir, "combined_output.txt")
with open(combined_output_path, "w", encoding="utf-8") as combined_out:
    for optimizer_name in optimizers.keys():
        output_file = os.path.join(results_dir, f"output_{optimizer_name}.txt")
        if os.path.exists(output_file):
            with open(output_file, "r", encoding="utf-8") as f:
                content = f.read()
            combined_out.write(f"=== Optimizer: {optimizer_name} ===\n")
            combined_out.write(content + "\n")
\end{tcblisting}

\subsubsection{Deletion of Temporary Files}
Once the individual data has been centralized, the temporary output files are deleted to reduce disk space usage and clean the results directory.

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Deletion of Temporary Files, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
for optimizer_name in optimizers.keys():
    output_file = os.path.join(results_dir, f"output_{optimizer_name}.txt")
    if os.path.exists(output_file):
        os.remove(output_file)
\end{tcblisting}

\subsubsection{Generation of Final Results}
The final results, such as the optimized energy, differences from the exact energy, and final molecular geometries, are presented to the user. Additionally, execution times and corresponding quantum circuits are visualized.

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Generation of Final Results, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize,
    stepnumber=1, numbersep=8pt, breaklines=true}}
print("=== Total Optimization Times ===\n")
for optimizer_name in optimizers.keys():
    final_energy = interface_results[optimizer_name]["final_energy"]
    exact_energy_ref = interface_results[optimizer_name]["exact_energy_reference"]
    diff = final_energy - exact_energy_ref if final_energy is not None else None
    if final_energy is not None:
        print(f"Final energy with {optimizer_name} = {final_energy:.8f} Ha")
        print(f"Difference from exact (FCI) energy: {diff:.8e} Ha\n")
    else:
        print(f"No final energy obtained with {optimizer_name}\n")

    total_time = interface_results[optimizer_name]["execution_times"].get('Total Time', 0)
    print(f"Optimizer: {optimizer_name}, Time: {total_time:.2f} seconds")
\end{tcblisting}

In this way, the complete workflow allows:
\begin{itemize}
    \item Executing processes in parallel and collecting their results.
    \item Unifying the generated data into a single output file.
    \item Cleaning up temporary files to maintain an organized directory.
    \item Presenting the final results in a clear and detailed manner.
\end{itemize}


\section{Limitations and Mitigation Measures}

Among the limitations of this approach are:
\begin{itemize}
    \item \textbf{Scalability:} As the system grows in the number of electrons and orbitals, the complexity of Hamiltonian construction and the excitation space increases exponentially.
    \item \textbf{Quantum Noise and Errors:} On real devices, noise affects measurement fidelity. Our work, primarily simulation-oriented, plans to integrate mitigation techniques in future studies.
    \item \textbf{Ansatz Choice:} Although the adaptive ansatz helps, there is no guarantee that the excitation selection is optimal. Future work might explore more complex heuristics.
\end{itemize}

To mitigate these issues, we opted for reduced basis sets, strategies such as re-initializing the optimizer when increasing the parameter space, and verifying convergence through multiple criteria (energetic and geometric).

\section{Version Control}
Git was employed for version control, enabling detailed tracking of code changes and ongoing collaboration with project supervisors. Initially, a single branch was used for development and exploration. Once a stable version was established, branches were created for testing and adding new features. The first branches were dedicated to different interface versions, each refined to ensure consistent performance across all interfaces. Ultimately, only the most suitable interface adjustments were merged back into the main branch.