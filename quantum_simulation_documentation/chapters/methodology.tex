%%%% PLEASE REPLACE ENTIRELY WITH YOUR OWN CONTENT %%%%


\chapter{Methodology / project development}

In this chapter, the methodology used in the completion of the work will be detailed. Its aim is to offer a thorough account of the approaches and techniques used, ensuring replicability and academic rigor. It will not only cover the research methods and measurement techniques employed but will also delve into the specifics of software and hardware development. Whether the project involves qualitative analysis, quantitative measurements, computational modeling, or physical prototyping, this chapter should elucidate how each component contributes to the overall objectives.

In addition to describing the methods themselves, the chapter will also provide justifications for why specific methods were chosen over others. For example, it may explain the choice of a particular programming language, statistical test, or experimental setup. The chapter will also address the limitations of the methodology and how these have been mitigated or accounted for. Readers should come away with a clear understanding of how the project's development has been carried out, why certain choices were made, and how these methods serve to fulfill the initially established objectives.

\section{Tools and Frameworks Selection} 
\subsection{Framework Selection}
To make the decision on which framework to use, we compared the documentation of the two quantum simulation frameworks available in the market: PennyLane and Qiskit. These are the most comprehensive frameworks with similar features available at the time of creating this project. After reviewing the documentation, we ultimately chose to use PennyLane for two reasons.

The first reason was the amount of documentation related to quantum simulation. Once we started looking into how others were using these resources, we realized that in the field of molecular simulation, the existing documentation—both theoretical and especially practical—was substantially greater. This provided us with more examples to begin developing our project.

The second reason for our choice was the frequent major changes implemented by Qiskit. We realized that while Qiskit is a tool that promises to be very good, it has historically undergone significant structural changes.

For these reasons, this project has been developed using the PennyLane framework. Below, we will observe how the project has been developed and explain the reasons behind the decisions made.

\section{Project Structuring}

After deciding on the interface to use and implementing the first version of the code, we decided to reorganize the project to make it more precise and modular. This structure offers the possibility to easily add more lines of code and functionalities.
\subsection{Code Organization}
\begin{ProjectStructure}
  \texttt{quantum\_simulation\_project/}
  \begin{itemize}[label={}, left=1em]
      \item \texttt{config/}
      \begin{itemize}[label={}, left=2em]
          \item \texttt{config\_functions.py}: Configuration functions for the project.
          \item \texttt{molecules.json}: Molecule data.
          \item \texttt{\_\_pycache\_\_}: Python cache files.
      \end{itemize}
      \item \texttt{main.py}: Main program file.
      \item \texttt{modules/}
      \begin{itemize}[label={}, left=2em]
          \item \texttt{ansatz\_preparer.py}: Quantum ansatz preparation.
          \item \texttt{hamiltonian\_builder.py}: Molecular Hamiltonian construction.
          \item \texttt{molecule\_manager.py}: Molecular data management.
          \item \texttt{opt\_mol.py}: Molecular optimization.
          \item \texttt{optimizer.py}: Optimization algorithms.
          \item \texttt{visualizer.py}: Visualization tools.
          \item \texttt{\_\_pycache\_\_}: Python cache files.
      \end{itemize}
      \item \texttt{temp\_results\_autograd/}
      \begin{itemize}[label={}, left=2em]
          \item \texttt{energy\_evolution.png}: Energy evolution graph.
          \item \texttt{filtered\_report\_autograd.txt}: Filtered results report.
          \item \texttt{final\_geometries\_3D.png}: Image of the final 3D geometries.
          \item \texttt{nuclear\_coordinates.png}: Nuclear coordinates.
          \item \texttt{output.txt}: Program data output.
          \item \texttt{profile\_output\_autograd.txt}: Autograd profile output.
      \end{itemize}
      \item \texttt{test/}: Directory for tests.
  \end{itemize}
\end{ProjectStructure}

This file serves as the entry point of the program. It initializes the initial conditions, sets up the molecule's configuration, defines optimization options, and orchestrates the execution of the quantum simulation and geometry optimization process. It is the first file to execute when running the application.

\textbf{Auxiliary Modules (\texttt{modules/})}:  
This directory contains various modules that encapsulate the core logic and operations of the project:
\begin{itemize}
    \item \texttt{ansatz\_preparer.py}: Includes functions for constructing the quantum circuit from the variational ansatz, preparing states, and applying excitations.
    \item \texttt{hamiltonian\_builder.py}: Responsible for generating the molecular Hamiltonian based on nuclear coordinates and the selected electronic basis.
    \item \texttt{molecule\_manager.py}: Manages information related to the molecule, such as its charge, multiplicity, number of electrons, and required orbitals.
    \item \texttt{opt\_mol.py}: Functions that orchestrate the molecular optimization process, invoking the optimizer and recording the simulation's progress.
    \item \texttt{optimizer.py}: Implements the optimization logic, combining routines for evaluating the cost (energy) with the selected optimization algorithms, updating parameters, and geometries.
    \item \texttt{visualizer.py}: Generates graphical outputs and reports that display the evolution of energy, nuclear coordinates, and other relevant data during optimization.
\end{itemize}

\textbf{Temporary Results Directories (\texttt{temp\_results\_autograd})}:  
    Several directories with names starting with \texttt{temp\_results\_autograd} store output data, time logs, and visualizations generated for different simulations and configurations. For documentation purposes, these directories are treated as a single repository for temporary results.

\textbf{Dependencies (\texttt{requirements.txt})}:  
    This file lists the required libraries and their versions to reproduce the project's execution environment. Keeping it updated ensures reproducibility of the simulation across different systems, facilitating the installation of necessary dependencies.


\subsection{Version Control}

Version control was managed using Git, allowing detailed tracking of changes and facilitating continuous collaboration with the supervisors on the project. Primarily, at the start of the project, a single branch was used to develop the project and explore the framework's possibilities. Once a stable version was achieved, branches were created to conduct tests and develop new functionalities. The first branches created were for the different interface versions. In each branch, the code was refined so that the same code would run across the various interfaces. Finally, only the interface changes that proved most suitable for the project were merged back into the main branch.

\section{Development and Implementation}

The \textit{Variational Quantum Eigensolver} (VQE) was chosen as the primary method to estimate the ground state energy of the studied quantum system. VQE combines limited quantum processing (measurements and applicability in moderately deep circuits) with classical optimization techniques. Its selection is justified by:

\begin{itemize}
    \item \textbf{Suitability for NISQ devices:} VQE is particularly well-suited for noisy intermediate-scale quantum (NISQ) devices, as it requires circuits of relatively low depth.
    \item \textbf{Flexible Ansatz:} It allows the use of various adaptive variational ansätze that capture essential electronic correlations.
    \item \textbf{Direct coupling to classical optimizers:} The VQE cost function (the expected energy) can be minimized with a wide range of classical methods, making it easy to experiment with different optimizers.
\end{itemize}

The core principle of VQE is the variational theorem, which guarantees that the expected energy of the ansatz is always an upper bound to the true ground state energy. By optimizing the ansatz parameters, the algorithm progressively approaches the actual energy minimum. We have already explained the concept of VQE in the state of the art chapter; now we will explain how we have implemented it in our project and how we have integrated it.

\paragraph{Principle of VQE:}

The VQE is based on the variational principle, which states that the expected energy of any approximate state \( |\psi(\theta)\rangle \) is always greater than or equal to the real ground state energy \( E_0 \):

\[
E(\theta) = \langle \psi(\theta) | H | \psi(\theta) \rangle \geq E_0
\]

We have already discussed this concept, but it is necessary to emphasize it as it is the foundation of the entire algorithm. The idea is to find the parameters \( \theta \) that minimize the expected energy, thereby approaching the real value of the ground state energy.

\bigskip

Next, we will detail how the VQE is implemented in our project, explaining how each component has been developed for trying to achieve the best performance and results.
\subsection{Hamiltonian Construction Process}

\begin{enumerate}
    \item \textbf{Definition of Molecular Geometry:}
    
    The geometry is specified by the atomic symbols and the Cartesian coordinates of each atom in the molecule:
    
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
      title=Geometry Definition, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
      listing options={language=Python, basicstyle=\ttfamily\small,
      showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt}}
symbols = ['H', 'H']
x_init = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.74]) 
    \end{tcblisting}
    
    
    \item \textbf{Hamiltonian Construction:}
    
    The \texttt{build\_hamiltonian} function generates the molecular Hamiltonian using PennyLane's functions:
    
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
      title=Hamiltonian Build, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
      listing options={language=Python, basicstyle=\ttfamily\small,
      showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt}}
def build_hamiltonian(x, symbols, charge=0, mult=1, basis_name='sto-3g'):
    x = np.array(x)
    coordinates = x.reshape(-1, 3)
    hamiltonian, qubits = qml.qchem.molecular_hamiltonian(
        symbols, coordinates, charge=charge, mult=mult, basis=basis_name
    )
    h_coeffs, h_ops = hamiltonian.terms()
    h_coeffs = np.array(h_coeffs)
    hamiltonian = qml.Hamiltonian(h_coeffs, h_ops)
    return hamiltonian
    \end{tcblisting}
    \textbf{Note:}
    A basis set, such as 'sto-3g', is selected, which is a predefined set of basis functions to represent atomic orbitals in a simplified manner. This makes the simulation more efficient.
    
    \textbf{Function Description:}
    
    This function generates the qubit Hamiltonian of a molecule by transforming the electronic Hamiltonian in second quantization into the Pauli matrix framework. Additionally, it allows for the incorporation of net charge effects, spin multiplicity, and an active space defined by a specific number of electrons and orbitals, optimizing the quantum simulation of molecular systems.
    
\end{enumerate}

\subsection{Adaptive Ansatz Construction and Operator Selection}

As we said before, the adaptive ansatz construction builds upon the conventional variational approach by strategically selecting only those excitations that offer the most significant energy reductions. Instead of starting from a large, fixed set of parameters, the algorithm begins with the Hartree-Fock state and incrementally introduces new excitations based on their calculated impact on lowering the system’s energy. This methodology provides both theoretical and practical advantages in handling the complexity of the solution space.

The selection process begins with a predefined \textit{operator pool}, typically composed of single and double excitation operators relevant to the molecular system. At the start of the procedure, no variational parameters are assigned, and the system is initialized in the reference Hartree-Fock state. At each iteration, the algorithm evaluates the energy gradients associated with adding each operator from the pool:

\begin{enumerate}
    \item \textbf{Gradient Calculation:} For every candidate operator $\hat{O}_i$ in the pool, the partial derivative of the energy with respect to the parameter controlling $\hat{O}_i$ is computed. This step identifies how sensitive the energy is to introducing that particular excitation.
    \item \textbf{Operator Ranking and Filtering:} All candidate excitations are ranked according to the absolute value of their gradients. Operators that produce negligible energy changes are discarded, while those offering substantial decreases are selected for inclusion.
    \item \textbf{Incremental Ansatz Growth:} The selected operator(s) is then added to the ansatz. A new parameter is introduced and optimized, increasing the dimensionality of the parameter space \emph{only where it matters}. This targeted expansion ensures that each additional parameter contributes meaningfully to lowering the energy.
    \item \textbf{Pool Update and Iteration:} After adding the chosen operators, the process repeats. The operator pool is re-examined at subsequent steps, but it now excludes previously chosen operators unless they are included as parameterized parts of the ansatz. Over multiple iterations, the ansatz evolves adaptively, honing in on the most relevant subset of excitations.
\end{enumerate}

A simplified code snippet, consistent with the project’s structure, may appear as follows:

\begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
  title=Adaptive Operator Selection, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
  listing options={language=Python, basicstyle=\ttfamily\small,
  showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt}}
gradients = compute_operator_gradients(operator_pool, selected_excitations, params, hamiltonian, hf_state, dev, spin_orbitals)
selected_gate, max_grad_value = select_operator(gradients, operator_pool, convergence_threshold)
if selected_gate:
    selected_excitations.append(selected_gate)
    params = np.append(params, 0.0)  # Add new parameter for the chosen operator
    print(f"Added operator {selected_gate} with gradient {max_grad_value:.5e}")
else:
    print("No significant operators found. Convergence or local minimum reached.")
\end{tcblisting}

In this code, the \texttt{compute\_operator\_gradients} function evaluates each operator’s gradient, while the \texttt{select\_operator} function applies a filtering criterion based on a defined \texttt{convergence\_threshold}. Only the most promising excitation is incorporated into the ansatz at each step, ensuring a controlled and meaningful expansion of the parameter space.

In numerical experiments, this targeted approach has demonstrated:
\begin{itemize}
    \item \textbf{Faster Convergence:} Fewer parameters are introduced at each stage, allowing the optimizer to quickly reduce the energy without wading through irrelevant configurations.
    \item \textbf{Lower Resource Consumption:} By refining the search space, the quantum circuits remain relatively shallow, and classical optimization routines require fewer evaluations.
    \item \textbf{Scalability:} As molecular systems grow in complexity, the adaptive approach helps mitigate the exponential growth in parameter number, making it more feasible to handle larger systems within similar computational budgets.
\end{itemize}


\subsection{Cost Function Definition}
With the ansatz defined, the next step is to establish a cost function that evaluates the expected energy of the system given a set of parameters \(\theta\). In our implementation, this cost function is defined within \texttt{update\_parameters\_and\_coordinates} and calculates the expected value of the molecular Hamiltonian:
  
  \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
    title=Definition of the Cost Function, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
    listing options={language=Python, basicstyle=\ttfamily\small,
    showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt}}
@qml.qnode(dev, interface=interface)
def cost_fn(params):
    prepare_ansatz(params, hf_state, selected_excitations, spin_orbitals)
    return qml.expval(hamiltonian)
  \end{tcblisting}
  
This function is essential for evaluating \(E(\theta)\). By calculating the expected value of the Hamiltonian, we can quantify how close our approximate state is to the true ground state.

\subsection{Mixed Electronic and Geometric Optimization Strategy}

In our project, we made a deliberate decision to integrate the refinement of both variational parameters \(\theta\) and nuclear coordinates \(\mathbf{X}\) into a single iterative loop. Rather than treating these aspects separately, as is common in sequential optimization approaches, we chose to couple the electronic and geometric optimizations from the start. By doing so, we ensured that each electronic update immediately reflects the current molecular geometry, and each geometric adjustment leverages the most recent and accurate electronic wavefunction. This approach was guided by our goal of finding the global minimum of the molecular system’s total energy more efficiently, ultimately steering the molecule towards its equilibrium geometry and ground state energy in a more coherent and resource-effective manner.

\paragraph{Rationale for Our Mixed Approach}
In many standard methodologies, the electronic structure is optimized at a fixed geometry before the geometry itself is optimized under that electronic configuration. We felt this separation was inefficient for our objectives, as it often leads to unnecessary iterations and suboptimal intermediate solutions. Recognizing that the electronic configuration and nuclear arrangement are intrinsically linked, we decided to continually update both in tandem. This choice was grounded in our understanding that capturing the interplay between the electronic distribution and molecular geometry as it unfolds would reduce computational overhead and converge more rapidly to a stable, physically meaningful equilibrium.

\paragraph{Our Iterative Optimization Steps}
\begin{enumerate}
    \item \textbf{Initialization:}
    We begin by defining the initial molecular geometry, nuclear coordinates \(\mathbf{X}_0\), and variational parameters \(\theta_0\). For instance:
    \begin{tcblisting}{colback=gray!5!white,colframe=gray!75!black,listing only,
      title=Initialization Example, fonttitle=\bfseries, breakable, enhanced jigsaw, leftupper=8mm,
      listing options={language=Python, basicstyle=\ttfamily\small,
      showstringspaces=false, numbers=left, numberstyle=\footnotesize, stepnumber=1, numbersep=8pt}}
symbols = ['H', 'H']
x_init = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.74])
params = np.array([], requires_grad=True)
    \end{tcblisting}
    We selected these initial values based on known molecular structures and our desire to start from a configuration that is simple yet representative.

    \item \textbf{Molecular Hamiltonian Update:}
    At each iteration, we recalculate the molecular Hamiltonian \(\hat{H}(\mathbf{X})\) using the updated nuclear coordinates. This ensures that our cost function (the expected energy) accurately reflects the current geometry at every step, allowing us to maintain a closer link between the electronic solution and the evolving molecular shape.

    \item \textbf{Operator Gradient Calculation and Selection:}
    For the electronic part, we compute energy gradients with respect to a pool of candidate excitation operators. We then select and add only the operator with the highest gradient contribution to the ansatz. This choice was made to keep the parameter space as manageable as possible, focusing our resources on the excitations that yield the greatest energy reductions. By gradually expanding the ansatz in this manner, we prevent an explosion in complexity and retain a more controlled optimization path.

    \item \textbf{Nuclear Gradient Computation and Coordinate Updates:}
    To update the nuclear coordinates \(\mathbf{X}\), we decided to compute the nuclear gradients numerically using finite differences. Concretely, for each coordinate direction, we slightly perturb \(\mathbf{X}\) and measure the resulting change in energy:
    \begin{equation}
    \nabla_{\mathbf{X}} E(\theta, \mathbf{X}) \approx \frac{E(\theta, \mathbf{X} + \delta \mathbf{u}) - E(\theta, \mathbf{X} - \delta \mathbf{u})}{2\delta}.
    \end{equation}
    We adopted this finite-difference method to maintain flexibility and simplicity, and because it integrates seamlessly with our adaptive approach. After obtaining the gradients, we update the coordinates as:
    \begin{equation}
    \mathbf{X}_{\text{new}} = \mathbf{X}_{\text{old}} - \alpha \nabla_{\mathbf{X}}E(\theta, \mathbf{X}),
    \end{equation}
    where \(\alpha\) is a learning rate we chose based on preliminary tests to balance stability and speed of convergence. This direct control allowed us to refine the geometry efficiently without overshooting or requiring overly complex gradient estimations.

    \item \textbf{Geometric Convergence Validation:}
    We established convergence criteria tailored to our desired precision and computational budget. For energy convergence, we require that differences between subsequent iterations fall below a small threshold (e.g., \(10^{-8}\) Ha). For geometric convergence, we set clear tolerances on changes in atomic positions and interatomic distances. Meeting both criteria ensures the geometry is near equilibrium and that no further improvements are necessary. This choice reflects our priority for a stable and physically meaningful final configuration rather than just a numerically optimized one.

    \item \textbf{Visualization and Termination:}
    Throughout the process, we record the evolving energy, coordinates, and other metrics. We decided to include immediate visual feedback (such as energy vs. iteration plots and 3D molecular views) to quickly assess the effectiveness of our approach. This real-time monitoring helps us recognize potential issues early, adjust our strategies, and confirm when we have reached the desired convergence criteria. Once these conditions are met, we terminate the process, confident that the final geometry and electronic state are both well-optimized.
\end{enumerate}

\paragraph{Why Our Iterative Coupling Is More Efficient}
By integrating electronic and geometric optimizations, we reduce the redundant recalculations and needless complexity that can arise in standard sequential methods. In our approach, each update to the electronic parameters leverages a geometry that is already moving towards equilibrium, and each geometric refinement uses an increasingly accurate electronic state. This synergy not only shortens the pathway to convergence but also helps us avoid getting stuck in suboptimal configurations. In our experience, this mixed strategy has proven more efficient and more closely aligned with the underlying physics of the system, delivering faster, more stable, and more accurate results than what we would expect from a traditional, decoupled optimization approach.

\section{Limitations and Mitigation Measures}

Among the limitations of this approach are:
\begin{itemize}
    \item \textbf{Scalability:} As the system grows in the number of electrons and orbitals, the complexity of Hamiltonian construction and the excitation space increases exponentially.
    \item \textbf{Quantum Noise and Errors:} On real devices, noise affects measurement fidelity. Our work, primarily simulation-oriented, plans to integrate mitigation techniques in future studies.
    \item \textbf{Ansatz Choice:} Although the adaptive ansatz helps, there is no guarantee that the excitation selection is optimal. Future work might explore more complex heuristics.
\end{itemize}

To mitigate these issues, we opted for reduced basis sets, strategies such as re-initializing the optimizer when increasing the parameter space, and verifying convergence through multiple criteria (energetic and geometric).
